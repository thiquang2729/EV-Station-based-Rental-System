# H∆∞·ªõng D·∫´n C·∫•u H√¨nh Apache NiFi cho Whitehouse Database

## M·ª•c L·ª•c
1. [T·ªïng Quan](#t·ªïng-quan)
2. [C·∫•u H√¨nh K·∫øt N·ªëi Database](#c·∫•u-h√¨nh-k·∫øt-n·ªëi-database)
3. [Flow 1: Extract v√† Load Booking Data](#flow-1-extract-v√†-load-booking-data)
4. [Flow 2: Extract v√† Load Payment Data](#flow-2-extract-v√†-load-payment-data)
5. [Flow 3: Populate Dimension Tables](#flow-3-populate-dimension-tables)
6. [Flow 4: Aggregate Daily Stats](#flow-4-aggregate-daily-stats)
7. [Flow 5: Calculate Peak Hours](#flow-5-calculate-peak-hours)
8. [Schedule v√† Automation](#schedule-v√†-automation)
9. [Monitoring v√† Troubleshooting](#monitoring-v√†-troubleshooting)
10. [Best Practices](#best-practices)

---

## T·ªïng Quan

Apache NiFi ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ:
- **Extract**: L·∫•y d·ªØ li·ªáu t·ª´ c√°c service databases (booking, payment, auth)
- **Transform**: Chuy·ªÉn ƒë·ªïi v√† l√†m s·∫°ch d·ªØ li·ªáu
- **Load**: ƒê∆∞a d·ªØ li·ªáu v√†o whitehouse database (data warehouse)

### Ki·∫øn Tr√∫c
```
[Booking DB] ‚îÄ‚îÄ‚îê
[Payment DB] ‚îÄ‚îÄ‚îº‚îÄ‚îÄ> [NiFi] ‚îÄ‚îÄ> [Whitehouse DB]
[Auth DB]   ‚îÄ‚îÄ‚îò
```

---

## C·∫•u H√¨nh K·∫øt N·ªëi Database

### 1. T·∫°o DBCPConnectionPool Controllers

#### 1.1. Booking Database Connection
1. V√†o **Controller Services** (bi·ªÉu t∆∞·ª£ng ‚öôÔ∏è ·ªü thanh toolbar)
2. Click **+** ƒë·ªÉ t·∫°o service m·ªõi
3. Ch·ªçn **DBCPConnectionPool**
4. ƒê·∫∑t t√™n: `BookingDBConnection`
5. C·∫•u h√¨nh:
   - **Database Connection URL**: `jdbc:mysql://booking-mysql:3306/evrental?useSSL=false&allowPublicKeyRetrieval=true`
   - **Database Driver Class Name**: `com.mysql.cj.jdbc.Driver`
   - **Database Driver Location(s)**: `/opt/nifi/nifi-current/lib/mysql-connector-java-8.0.33.jar`
   - **Database User**: `evuser`
   - **Password**: `evpass`
   - **Max Total Connections**: `10`
   - **Max Idle Connections**: `5`
   - **Min Idle Connections**: `2`
   - **Validation Query**: `SELECT 1`

#### 1.2. Payment Database Connection
- T√™n: `PaymentDBConnection`
- **Database Connection URL**: `jdbc:mysql://billing-mysql:3306/evrental?useSSL=false&allowPublicKeyRetrieval=true`
- **Database User**: `root`
- **Password**: `root`
- C√°c settings kh√°c gi·ªëng Booking DB

#### 1.3. Auth Database Connection
- T√™n: `AuthDBConnection`
- **Database Connection URL**: `jdbc:mysql://auth-mysql:3306/xdhdt?useSSL=false&allowPublicKeyRetrieval=true`
- **Database User**: `root` (ho·∫∑c user t∆∞∆°ng ·ª©ng)
- **Password**: `root` (ho·∫∑c password t∆∞∆°ng ·ª©ng)

#### 1.4. Whitehouse Database Connection
- T√™n: `WhitehouseDBConnection`
- **Database Connection URL**: `jdbc:mysql://whitehouse-mysql:3306/whitehouse?useSSL=false&allowPublicKeyRetrieval=true`
- **Database User**: `nifi`
- **Password**: `nifi123`
- **Max Total Connections**: `20` (v√¨ s·∫Ω c√≥ nhi·ªÅu write operations)

### 2. Enable Controllers
- Click v√†o t·ª´ng controller service v√† click **Enable** (bi·ªÉu t∆∞·ª£ng ‚ñ∂Ô∏è)

---

## Flow 1: Extract v√† Load Booking Data

### M·ª•c ƒê√≠ch
Extract booking data t·ª´ booking database v√† load v√†o `fact_booking` v√† staging tables.

### ‚ö° C·∫§U H√åNH REAL-TIME (Near Real-Time Updates)

ƒê·ªÉ NiFi t·ª± ƒë·ªông c·∫≠p nh·∫≠t m·ªói khi database thay ƒë·ªïi, s·ª≠ d·ª•ng **QueryDatabaseTable** v·ªõi **Maximum-value Columns** v√† polling interval ng·∫Øn.

### C√°c Processors C·∫ßn T·∫°o

#### 1.1. QueryDatabaseTable (Real-Time Polling)
- **Name**: `ExtractBookingsRealtime`
- **Controller Service**: `BookingDBConnection`
- **Table Name**: `Booking`
- **Columns to Return**: `id, userId, vehicleId, stationId, startTime, endTime, status, priceEstimate, priceFinal, paymentId, createdAt, updatedAt`
- **Maximum-value Columns**: `updatedAt` ‚≠ê (QUAN TR·ªåNG: ƒê·ªÉ incremental load)
- **Where Clause**: `status IN ('CONFIRMED', 'COMPLETED', 'CANCELLED')`
- **Scheduling Strategy**: `Timer driven`
- **Run Schedule**: `30 sec` (ho·∫∑c `1 min` - check m·ªói 30 gi√¢y ho·∫∑c 1 ph√∫t)
- **Concurrent Tasks**: `1`
- **Max Rows Per Flow File**: `1000` (ƒë·ªÉ tr√°nh flowfile qu√° l·ªõn)

**C√°ch ho·∫°t ƒë·ªông:**
- NiFi s·∫Ω l∆∞u gi√° tr·ªã `updatedAt` l·ªõn nh·∫•t ƒë√£ x·ª≠ l√Ω
- M·ªói l·∫ßn ch·∫°y, ch·ªâ query c√°c records c√≥ `updatedAt > gi√° tr·ªã ƒë√£ l∆∞u`
- T·ª± ƒë·ªông c·∫≠p nh·∫≠t gi√° tr·ªã m·ªõi sau m·ªói l·∫ßn query th√†nh c√¥ng

#### 1.2. ConvertRecord (JSON to Avro/JSON)
- **Name**: `ConvertBookingToJSON`
- **Record Reader**: `JsonTreeReader`
- **Record Writer**: `JsonRecordSetWriter`

#### 1.3. UpdateAttribute
- **Name**: `SetBookingAttributes`
- Th√™m attributes:
  - `booking.table`: `fact_booking`
  - `booking.operation`: `INSERT`

#### 1.4. PutSQL
- **Name**: `LoadBookingsToStaging`
- **Controller Service**: `WhitehouseDBConnection`
- **SQL Statement**:
```sql
INSERT INTO staging_booking (
  booking_id, user_id, vehicle_id, station_id, 
  start_time, end_time, status, price_estimate, 
  price_final, payment_id, created_at, updated_at
) VALUES (
  ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?
)
ON DUPLICATE KEY UPDATE
  user_id = VALUES(user_id),
  vehicle_id = VALUES(vehicle_id),
  station_id = VALUES(station_id),
  start_time = VALUES(start_time),
  end_time = VALUES(end_time),
  status = VALUES(status),
  price_estimate = VALUES(price_estimate),
  price_final = VALUES(price_final),
  payment_id = VALUES(payment_id),
  updated_at = VALUES(updated_at)
```

#### 1.5. ExecuteSQL
- **Name**: `TransformStagingToFactBooking`
- **SQL Statement**:
```sql
INSERT INTO fact_booking (
  booking_id, time_id, user_id, station_id, vehicle_id,
  start_time, end_time, status, price_estimate, price_final,
  payment_id, duration_hours
)
SELECT 
  sb.booking_id,
  dt.time_id,
  sb.user_id,
  sb.station_id,
  sb.vehicle_id,
  sb.start_time,
  sb.end_time,
  sb.status,
  sb.price_estimate,
  sb.price_final,
  sb.payment_id,
  CASE 
    WHEN sb.end_time IS NOT NULL AND sb.start_time IS NOT NULL 
    THEN TIMESTAMPDIFF(HOUR, sb.start_time, sb.end_time)
    ELSE NULL
  END as duration_hours
FROM staging_booking sb
INNER JOIN dim_time dt ON DATE(sb.start_time) = dt.date
WHERE sb.status IN ('CONFIRMED', 'COMPLETED')
ON DUPLICATE KEY UPDATE
  time_id = VALUES(time_id),
  user_id = VALUES(user_id),
  station_id = VALUES(station_id),
  vehicle_id = VALUES(vehicle_id),
  start_time = VALUES(start_time),
  end_time = VALUES(end_time),
  status = VALUES(status),
  price_estimate = VALUES(price_estimate),
  price_final = VALUES(price_final),
  payment_id = VALUES(payment_id),
  duration_hours = VALUES(duration_hours)
```

### K·∫øt N·ªëi Processors (Real-Time)
```
ExtractBookingsRealtime ‚Üí ConvertBookingToJSON 
‚Üí SetBookingAttributes ‚Üí LoadBookingsToStaging ‚Üí TransformStagingToFactBooking
```

**L∆∞u √Ω:** Kh√¥ng c·∫ßn `GenerateFlowFile` v√¨ `QueryDatabaseTable` t·ª± ƒë·ªông trigger khi c√≥ data m·ªõi.

### ‚öôÔ∏è C·∫•u H√¨nh State Management

`QueryDatabaseTable` s·∫Ω t·ª± ƒë·ªông l∆∞u state (gi√° tr·ªã `updatedAt` l·ªõn nh·∫•t) trong NiFi State Manager. ƒê·ªÉ reset state:
1. Click processor ‚Üí Tab **State Management**
2. Click **Clear State** n·∫øu mu·ªën reset v√† load l·∫°i t·ª´ ƒë·∫ßu
3. Ho·∫∑c x√≥a state file trong NiFi state directory

### üìä Monitoring Real-Time Flow

- **Queue Size**: Ki·ªÉm tra queue size c·ªßa `ExtractBookingsRealtime` - n·∫øu tƒÉng li√™n t·ª•c c√≥ nghƒ©a l√† x·ª≠ l√Ω kh√¥ng k·ªãp
- **FlowFiles In/Out**: S·ªë flowfiles ƒë√£ x·ª≠ l√Ω
- **Last Execution Time**: Th·ªùi gian ch·∫°y l·∫ßn cu·ªëi

---

## Flow 2: Extract v√† Load Payment Data

### M·ª•c ƒê√≠ch
Extract payment data t·ª´ payment database v√† load v√†o `fact_payment`.

#### 2.1. QueryDatabaseTable (Real-Time)
- **Name**: `ExtractPaymentsRealtime`
- **Controller Service**: `PaymentDBConnection`
- **Table Name**: `Payment`
- **Columns**: `id, renterId, bookingId, stationId, amount, status, method, type, transactionId, createdAt, updatedAt`
- **Maximum-value Columns**: `updatedAt` ‚≠ê (QUAN TR·ªåNG)
- **Where Clause**: `status = 'SUCCEEDED'`
- **Scheduling Strategy**: `Timer driven`
- **Run Schedule**: `30 sec` (ho·∫∑c `1 min`)
- **Concurrent Tasks**: `1`
- **Max Rows Per Flow File**: `1000`

#### 2.2. PutSQL
- **Name**: `LoadPaymentsToStaging`
- **SQL Statement**:
```sql
INSERT INTO staging_payment (
  payment_id, user_id, booking_id, station_id,
  amount, status, method, type, transaction_id,
  created_at, updated_at
) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
ON DUPLICATE KEY UPDATE
  user_id = VALUES(user_id),
  booking_id = VALUES(booking_id),
  station_id = VALUES(station_id),
  amount = VALUES(amount),
  status = VALUES(status),
  method = VALUES(method),
  type = VALUES(type),
  transaction_id = VALUES(transaction_id),
  updated_at = VALUES(updated_at)
```

#### 2.3. ExecuteSQL
- **Name**: `TransformStagingToFactPayment`
- **SQL Statement**:
```sql
INSERT INTO fact_payment (
  payment_id, time_id, user_id, station_id, booking_id,
  amount, status, method, transaction_id
)
SELECT 
  sp.payment_id,
  dt.time_id,
  sp.user_id,
  sp.station_id,
  sp.booking_id,
  sp.amount,
  sp.status,
  sp.method,
  sp.transaction_id
FROM staging_payment sp
INNER JOIN dim_time dt ON DATE(sp.created_at) = dt.date
WHERE sp.status = 'SUCCEEDED'
ON DUPLICATE KEY UPDATE
  time_id = VALUES(time_id),
  user_id = VALUES(user_id),
  station_id = VALUES(station_id),
  booking_id = VALUES(booking_id),
  amount = VALUES(amount),
  status = VALUES(status),
  method = VALUES(method),
  transaction_id = VALUES(transaction_id)
```

---

## Flow 3: Populate Dimension Tables

### 3.1. Populate DimStation

#### ExecuteSQL
- **Name**: `SyncDimStation`
- **Schedule**: `0 0 2 * * ?` (Ch·∫°y l√∫c 2h s√°ng)
- **SQL Statement**:
```sql
INSERT INTO dim_station (station_id, station_name, address, lat, lng)
SELECT 
  s.id as station_id,
  s.name as station_name,
  s.address,
  s.lat,
  s.lng
FROM booking-mysql.evrental.Station s
ON DUPLICATE KEY UPDATE
  station_name = VALUES(station_name),
  address = VALUES(address),
  lat = VALUES(lat),
  lng = VALUES(lng),
  updated_at = NOW()
```

### 3.2. Populate DimUser

#### ExecuteSQL
- **Name**: `SyncDimUser`
- **SQL Statement**:
```sql
INSERT INTO dim_user (user_id, email, full_name, phone_number, role, verification_status)
SELECT 
  u.id as user_id,
  u.email,
  u.fullName as full_name,
  u.phoneNumber as phone_number,
  u.role,
  u.verificationStatus as verification_status
FROM auth-mysql.xdhdt.User u
ON DUPLICATE KEY UPDATE
  email = VALUES(email),
  full_name = VALUES(full_name),
  phone_number = VALUES(phone_number),
  role = VALUES(role),
  verification_status = VALUES(verification_status),
  updated_at = NOW()
```

### 3.3. Populate DimVehicle

#### ExecuteSQL
- **Name**: `SyncDimVehicle`
- **SQL Statement**:
```sql
INSERT INTO dim_vehicle (vehicle_id, vehicle_name, plate, type, station_id, price_per_day)
SELECT 
  v.id as vehicle_id,
  v.name as vehicle_name,
  v.plate,
  v.type,
  v.stationId as station_id,
  v.pricePerDay as price_per_day
FROM booking-mysql.evrental.Vehicle v
ON DUPLICATE KEY UPDATE
  vehicle_name = VALUES(vehicle_name),
  plate = VALUES(plate),
  type = VALUES(type),
  station_id = VALUES(station_id),
  price_per_day = VALUES(price_per_day),
  updated_at = NOW()
```

### 3.4. Populate DimTime (N·∫øu ch∆∞a c√≥)

#### ExecuteSQL
- **Name**: `PopulateDimTime`
- **Schedule**: `0 0 0 1 1 ?` (Ch·∫°y m·ªói nƒÉm m·ªôt l·∫ßn v√†o 1/1)
- **SQL Statement**: G·ªçi stored procedure
```sql
CALL populate_dim_time(2)
```

---

## Flow 4: Aggregate Daily Stats

### M·ª•c ƒê√≠ch
T√≠nh to√°n v√† l∆∞u c√°c th·ªëng k√™ h√†ng ng√†y v√†o `agg_daily_stats`.

#### ExecuteSQL
- **Name**: `AggregateDailyStats`
- **Schedule**: `0 30 1 * * ?` (Ch·∫°y l√∫c 1h30 s√°ng m·ªói ng√†y)
- **SQL Statement**:
```sql
INSERT INTO agg_daily_stats (
  time_id, station_id,
  total_bookings, total_revenue, total_payments,
  completed_bookings, cancelled_bookings,
  avg_booking_duration_hours, unique_users, unique_vehicles
)
SELECT 
  dt.time_id,
  COALESCE(fb.station_id, fp.station_id) as station_id,
  COUNT(DISTINCT fb.booking_id) as total_bookings,
  COALESCE(SUM(fp.amount), 0) as total_revenue,
  COUNT(DISTINCT fp.payment_id) as total_payments,
  SUM(CASE WHEN fb.status = 'COMPLETED' THEN 1 ELSE 0 END) as completed_bookings,
  SUM(CASE WHEN fb.status = 'CANCELLED' THEN 1 ELSE 0 END) as cancelled_bookings,
  AVG(fb.duration_hours) as avg_booking_duration_hours,
  COUNT(DISTINCT fb.user_id) as unique_users,
  COUNT(DISTINCT fb.vehicle_id) as unique_vehicles
FROM dim_time dt
LEFT JOIN fact_booking fb ON dt.time_id = fb.time_id
LEFT JOIN fact_payment fp ON dt.time_id = fp.time_id AND fp.status = 'SUCCEEDED'
WHERE dt.date = DATE_SUB(CURDATE(), INTERVAL 1 DAY)
GROUP BY dt.time_id, COALESCE(fb.station_id, fp.station_id)
ON DUPLICATE KEY UPDATE
  total_bookings = VALUES(total_bookings),
  total_revenue = VALUES(total_revenue),
  total_payments = VALUES(total_payments),
  completed_bookings = VALUES(completed_bookings),
  cancelled_bookings = VALUES(cancelled_bookings),
  avg_booking_duration_hours = VALUES(avg_booking_duration_hours),
  unique_users = VALUES(unique_users),
  unique_vehicles = VALUES(unique_vehicles),
  updated_at = NOW()
```

---

## Flow 5: Calculate Peak Hours

### M·ª•c ƒê√≠ch
T√≠nh to√°n gi·ªù cao ƒëi·ªÉm v√† l∆∞u v√†o `fact_peak_hours`.

#### ExecuteSQL
- **Name**: `CalculatePeakHours`
- **Schedule**: `0 0 2 * * ?` (Ch·∫°y l√∫c 2h s√°ng)
- **SQL Statement**:
```sql
INSERT INTO fact_peak_hours (
  time_id, hour_of_day, station_id, vehicle_type,
  total_bookings, total_revenue, avg_duration_hours,
  unique_users, peak_score
)
SELECT 
  dt.time_id,
  HOUR(fb.start_time) as hour_of_day,
  fb.station_id,
  dv.type as vehicle_type,
  COUNT(DISTINCT fb.booking_id) as total_bookings,
  COALESCE(SUM(fp.amount), 0) as total_revenue,
  AVG(fb.duration_hours) as avg_duration_hours,
  COUNT(DISTINCT fb.user_id) as unique_users,
  (
    COUNT(DISTINCT fb.booking_id) * 0.4 +
    COALESCE(SUM(fp.amount), 0) / 1000000 * 0.3 +
    COUNT(DISTINCT fb.user_id) * 0.2 +
    AVG(fb.duration_hours) * 0.1
  ) as peak_score
FROM dim_time dt
INNER JOIN fact_booking fb ON dt.time_id = fb.time_id
LEFT JOIN dim_vehicle dv ON fb.vehicle_id = dv.vehicle_id
LEFT JOIN fact_payment fp ON fb.booking_id = fp.booking_id AND fp.status = 'SUCCEEDED'
WHERE dt.date = DATE_SUB(CURDATE(), INTERVAL 1 DAY)
  AND fb.status IN ('CONFIRMED', 'COMPLETED')
GROUP BY dt.time_id, HOUR(fb.start_time), fb.station_id, dv.type
ON DUPLICATE KEY UPDATE
  total_bookings = VALUES(total_bookings),
  total_revenue = VALUES(total_revenue),
  avg_duration_hours = VALUES(avg_duration_hours),
  unique_users = VALUES(unique_users),
  peak_score = VALUES(peak_score),
  updated_at = NOW()
```

---

## Schedule v√† Automation

### ‚ö° Real-Time vs Batch Processing

#### Option 1: Real-Time (Near Real-Time) - RECOMMENDED
S·ª≠ d·ª•ng **Timer driven** v·ªõi interval ng·∫Øn cho fact tables:

| Flow | Strategy | Schedule | M√¥ T·∫£ |
|------|----------|----------|-------|
| Extract Bookings | Timer driven | `30 sec` | Check m·ªói 30 gi√¢y |
| Extract Payments | Timer driven | `30 sec` | Check m·ªói 30 gi√¢y |
| Transform to Fact | Timer driven | `1 min` | Transform m·ªói ph√∫t |
| Sync Dimensions | Timer driven | `5 min` | Sync m·ªói 5 ph√∫t |
| Aggregate Stats | CRON driven | `0 0 1 * * ?` | Ch·∫°y 1h s√°ng (batch) |
| Calculate Peak Hours | CRON driven | `0 0 2 * * ?` | Ch·∫°y 2h s√°ng (batch) |

**∆Øu ƒëi·ªÉm:**
- ‚úÖ C·∫≠p nh·∫≠t g·∫ßn nh∆∞ real-time (delay 30s-1min)
- ‚úÖ T·ª± ƒë·ªông ph√°t hi·ªán thay ƒë·ªïi
- ‚úÖ Kh√¥ng c·∫ßn manual trigger

**Nh∆∞·ª£c ƒëi·ªÉm:**
- ‚ö†Ô∏è T·ªën t√†i nguy√™n h∆°n (query th∆∞·ªùng xuy√™n)
- ‚ö†Ô∏è C·∫ßn ƒë·∫£m b·∫£o database c√≥ index tr√™n `updatedAt`

#### Option 2: Batch Processing (Traditional)
S·ª≠ d·ª•ng **CRON driven** cho c√°c flows ch·∫°y theo l·ªãch:

| Flow | Schedule | M√¥ T·∫£ |
|------|----------|-------|
| Extract Bookings | `0 0 1 * * ?` | 1h s√°ng m·ªói ng√†y |
| Extract Payments | `0 15 1 * * ?` | 1h15 s√°ng m·ªói ng√†y |
| Sync Dimensions | `0 30 1 * * ?` | 1h30 s√°ng m·ªói ng√†y |
| Aggregate Stats | `0 45 1 * * ?` | 1h45 s√°ng m·ªói ng√†y |
| Calculate Peak Hours | `0 0 2 * * ?` | 2h s√°ng m·ªói ng√†y |
| Populate DimTime | `0 0 0 1 1 ?` | 1/1 m·ªói nƒÉm |

### Cron Expression Format
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ minute (0 - 59)
‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ hour (0 - 23)
‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ day of month (1 - 31)
‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ month (1 - 12)
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ day of week (0 - 6) (Sunday to Saturday)
‚îÇ ‚îÇ ‚îÇ ‚îÇ ‚îÇ
* * * * * ?
```

### C·∫•u H√¨nh Schedule trong NiFi

#### Timer Driven (Real-Time)
1. Click v√†o processor
2. Tab **Scheduling**
3. **Scheduling Strategy**: `Timer driven`
4. **Run Schedule**: `30 sec` ho·∫∑c `1 min`
5. **Run Duration**: `0 seconds`
6. **Concurrent Tasks**: `1`

#### CRON Driven (Batch)
1. Click v√†o processor
2. Tab **Scheduling**
3. **Scheduling Strategy**: `CRON driven`
4. **Cron Expression**: Nh·∫≠p expression t∆∞∆°ng ·ª©ng
5. **Run Duration**: `0 seconds`
6. **Concurrent Tasks**: `1`

---

## Monitoring v√† Troubleshooting

### 1. Ki·ªÉm Tra Flow Status

#### Bulletins
- V√†o **Bulletin Board** (bi·ªÉu t∆∞·ª£ng üì¢) ƒë·ªÉ xem warnings/errors

#### Processor Statistics
- Click processor ‚Üí Tab **Statistics**:
  - **In**: S·ªë flowfiles ƒë√£ nh·∫≠n
  - **Out**: S·ªë flowfiles ƒë√£ g·ª≠i
  - **Read/Write**: Bytes ƒë√£ x·ª≠ l√Ω
  - **Duration**: Th·ªùi gian x·ª≠ l√Ω

### 2. Common Issues

#### Issue: Connection Timeout
**Nguy√™n nh√¢n**: Database kh√¥ng accessible ho·∫∑c network issue
**Gi·∫£i ph√°p**:
- Ki·ªÉm tra database container ƒëang ch·∫°y: `docker ps | grep mysql`
- Test connection t·ª´ NiFi container: `docker exec nifi-container mysql -h host -u user -p`
- TƒÉng timeout trong DBCPConnectionPool settings

#### Issue: Duplicate Key Error
**Nguy√™n nh√¢n**: Data ƒë√£ t·ªìn t·∫°i trong staging/fact tables
**Gi·∫£i ph√°p**:
- S·ª≠ d·ª•ng `ON DUPLICATE KEY UPDATE` trong SQL
- Ho·∫∑c x√≥a data c≈© tr∆∞·ªõc khi insert: `DELETE FROM staging_booking WHERE DATE(created_at) = DATE_SUB(CURDATE(), INTERVAL 1 DAY)`

#### Issue: Missing Dimension Data
**Nguy√™n nh√¢n**: `dim_time` ho·∫∑c dimension tables ch∆∞a c√≥ data
**Gi·∫£i ph√°p**:
- Ch·∫°y `PopulateDimTime` stored procedure
- Sync dimension tables tr∆∞·ªõc khi load fact tables

#### Issue: Performance Slow
**Nguy√™n nh√¢n**: Qu√° nhi·ªÅu data ho·∫∑c query kh√¥ng t·ªëi ∆∞u
**Gi·∫£i ph√°p**:
- Th√™m indexes v√†o staging v√† fact tables
- S·ª≠ d·ª•ng incremental load (WHERE clause v·ªõi date range)
- TƒÉng connection pool size
- Ch·∫°y flows v√†o gi·ªù th·∫•p ƒëi·ªÉm

### 3. Logging v√† Debugging

#### Enable Logging
1. V√†o **Controller Settings** ‚Üí **Logging**
2. Set log level cho processors:
   - `org.apache.nifi.processors.standard.ExecuteSQL` ‚Üí `DEBUG`
   - `org.apache.nifi.processors.standard.QueryDatabaseTable` ‚Üí `DEBUG`

#### View Logs
```bash
docker logs nifi-container --tail 100 -f
```

#### Check Database
```sql
-- Ki·ªÉm tra s·ªë records trong staging
SELECT COUNT(*) FROM staging_booking;
SELECT COUNT(*) FROM staging_payment;

-- Ki·ªÉm tra s·ªë records trong fact tables
SELECT COUNT(*) FROM fact_booking;
SELECT COUNT(*) FROM fact_payment;

-- Ki·ªÉm tra latest data
SELECT MAX(created_at) FROM staging_booking;
SELECT MAX(created_at) FROM fact_booking;
```

---

## Best Practices

### 1. Real-Time Processing Best Practices

#### Database Indexes (QUAN TR·ªåNG)
ƒê·∫£m b·∫£o c√≥ index tr√™n `updatedAt` ƒë·ªÉ query nhanh:
```sql
-- Booking table
CREATE INDEX idx_updated_at ON Booking(updatedAt);
CREATE INDEX idx_status_updated ON Booking(status, updatedAt);

-- Payment table
CREATE INDEX idx_updated_at ON Payment(updatedAt);
CREATE INDEX idx_status_updated ON Payment(status, updatedAt);
```

#### Polling Interval
- **30 gi√¢y**: Cho data thay ƒë·ªïi th∆∞·ªùng xuy√™n (bookings, payments)
- **1-5 ph√∫t**: Cho data √≠t thay ƒë·ªïi (dimensions)
- **Kh√¥ng n√™n < 10 gi√¢y**: Tr√°nh overload database

#### State Management
- **Backup state**: NiFi state ƒë∆∞·ª£c l∆∞u trong `conf/state/` - n√™n backup ƒë·ªãnh k·ª≥
- **Clear state**: N·∫øu mu·ªën reload t·ª´ ƒë·∫ßu, clear state trong processor
- **State persistence**: ƒê·∫£m b·∫£o NiFi state directory ƒë∆∞·ª£c mount persistent

### 2. Data Quality
- **Validate data** tr∆∞·ªõc khi load v√†o fact tables
- **Handle NULL values** ƒë√∫ng c√°ch
- **Check referential integrity** (foreign keys)
- **Deduplicate**: S·ª≠ d·ª•ng `ON DUPLICATE KEY UPDATE` ƒë·ªÉ tr√°nh duplicate

### 3. Performance
- **Use staging tables** ƒë·ªÉ transform data tr∆∞·ªõc khi load v√†o fact
- **Index staging tables** tr√™n c√°c columns th∆∞·ªùng query
- **Batch inserts** thay v√¨ insert t·ª´ng record (Max Rows Per Flow File = 1000)
- **Incremental load** v·ªõi Maximum-value Columns
- **Connection pooling**: TƒÉng Max Connections trong DBCPConnectionPool

### 4. Error Handling
- **Use PutSQL v·ªõi error handling**: Set **Rollback On Failure** = `false`
- **Route failed flowfiles** ƒë·∫øn m·ªôt processor ƒë·ªÉ log errors
- **Retry mechanism**: S·ª≠ d·ª•ng RetryFlowFile processor
- **Dead Letter Queue**: L∆∞u failed records ƒë·ªÉ x·ª≠ l√Ω sau

### 5. Security
- **Store credentials** trong NiFi Registry ho·∫∑c environment variables
- **Use SSL** cho database connections (production)
- **Limit access** ƒë·∫øn NiFi UI
- **Network isolation**: ƒê·∫£m b·∫£o NiFi ch·ªâ c√≥ th·ªÉ k·∫øt n·ªëi ƒë·∫øn databases c·∫ßn thi·∫øt

### 6. Monitoring
- **Set up alerts** cho failed processors
- **Monitor queue sizes** (n·∫øu queue qu√° l·ªõn, c√≥ th·ªÉ c√≥ bottleneck)
- **Track data volume** m·ªói ng√†y ƒë·ªÉ ph√°t hi·ªán anomalies
- **Monitor database load**: Ki·ªÉm tra slow queries v√† connection count
- **Alert on state lag**: N·∫øu state kh√¥ng update trong X ph√∫t, c√≥ th·ªÉ c√≥ v·∫•n ƒë·ªÅ

---

## Sample Complete Flow

### Flow Diagram
```
[GenerateFlowFile] (Trigger daily at 1 AM)
    ‚Üì
[QueryDatabaseTable] (Extract Bookings)
    ‚Üì
[ConvertRecord] (JSON)
    ‚Üì
[UpdateAttribute] (Set metadata)
    ‚Üì
[PutSQL] (Load to staging_booking)
    ‚Üì
[ExecuteSQL] (Transform to fact_booking)
    ‚Üì
[LogAttribute] (Log success)
```

### Error Handling Flow
```
[PutSQL] (Load to staging)
    ‚îú‚îÄ Success ‚Üí [ExecuteSQL] (Transform)
    ‚îî‚îÄ Failure ‚Üí [PutFile] (Save error file)
                  ‚Üì
              [LogAttribute] (Log error)
```

---

## Quick Start Checklist

- [ ] T·∫°o 4 DBCPConnectionPool controllers (Booking, Payment, Auth, Whitehouse)
- [ ] Enable t·∫•t c·∫£ controllers
- [ ] T·∫°o Flow 1: Extract v√† Load Booking Data
- [ ] T·∫°o Flow 2: Extract v√† Load Payment Data
- [ ] T·∫°o Flow 3: Populate Dimension Tables
- [ ] T·∫°o Flow 4: Aggregate Daily Stats
- [ ] T·∫°o Flow 5: Calculate Peak Hours
- [ ] C·∫•u h√¨nh schedule cho t·ª´ng flow
- [ ] Test t·ª´ng flow v·ªõi sample data
- [ ] Monitor logs v√† statistics
- [ ] Verify data trong whitehouse database

---

## T√†i Li·ªáu Tham Kh·∫£o

- [NiFi User Guide](https://nifi.apache.org/docs.html)
- [NiFi Expression Language](https://nifi.apache.org/docs/nifi-docs/html/expression-language-guide.html)
- [MySQL JDBC Driver](https://dev.mysql.com/doc/connector-j/8.0/en/)
- [Cron Expression](https://www.freeformatter.com/cron-expression-generator-quartz.html)

---

## Li√™n H·ªá v√† H·ªó Tr·ª£

N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, ki·ªÉm tra:
1. NiFi logs: `docker logs nifi-container`
2. Database logs: `docker logs whitehouse-mysql`
3. Network connectivity: `docker network inspect ev-rental-network`
4. Processor bulletins trong NiFi UI

